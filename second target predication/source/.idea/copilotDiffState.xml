<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/model_comparer.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/model_comparer.py" />
              <option name="originalContent" value="# ============================================&#10;# STEP 3 — Compare feature importance + SHAP&#10;# ============================================&#10;import os&#10;import re&#10;import json&#10;import joblib&#10;import numpy as np&#10;import pandas as pd&#10;import shap&#10;import matplotlib.pyplot as plt&#10;import xgboost as xgb&#10;import seaborn as sns&#10;from scipy.stats import spearmanr, kendalltau, pearsonr&#10;import warnings&#10;from sklearn.metrics import roc_auc_score&#10;from sklearn.linear_model import LinearRegression&#10;from sklearn.preprocessing import StandardScaler&#10;from sklearn.pipeline import Pipeline&#10;from sklearn.linear_model import LogisticRegression&#10;&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;plt.rcParams['figure.dpi'] = 200&#10;plt.rcParams['savefig.dpi'] = 300&#10;plt.rcParams['font.size'] = 12&#10;&#10;# Define paths to the Classification and Regression folders&#10;CLASSIFICATION_DIR = './Classification'&#10;REGRESSION_DIR = './Regression'&#10;&#10;print(&quot;Starting model comparison analysis...&quot;)&#10;print(f&quot;Classification directory: {os.path.abspath(CLASSIFICATION_DIR)}&quot;)&#10;print(f&quot;Regression directory: {os.path.abspath(REGRESSION_DIR)}&quot;)&#10;&#10;# -----------------------------&#10;# 0) Load models and data&#10;# -----------------------------&#10;# Classifier (primary target: cardio)&#10;clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_enhanced.pkl')&#10;if not os.path.exists(clf_model_path):&#10;    clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_model.pkl')&#10;&#10;clf = joblib.load(clf_model_path)&#10;print(f&quot;\nLoaded classifier from: {clf_model_path}&quot;)&#10;&#10;# Try to load feature names for classifier from feature importance rankings&#10;try:&#10;    feature_rankings_path = os.path.join(CLASSIFICATION_DIR, 'feature_importance_rankings.csv')&#10;    if os.path.exists(feature_rankings_path):&#10;        feature_rankings = pd.read_csv(feature_rankings_path)&#10;        selected_cols_cls = feature_rankings['feature'].tolist()&#10;    else:&#10;        # Fallback: try to reconstruct from model&#10;        selected_cols_cls = [f'clf_feature_{i}' for i in range(clf.n_features_in_)]&#10;    print(f&quot;Loaded {len(selected_cols_cls)} classifier feature names&quot;)&#10;except Exception as e:&#10;    print(f&quot;Warning: Could not load classifier feature names: {e}&quot;)&#10;    if hasattr(clf, 'n_features_in_'):&#10;        selected_cols_cls = [f'clf_feature_{i}' for i in range(clf.n_features_in_)]&#10;    else:&#10;        raise RuntimeError(&quot;Classifier feature names cannot be determined&quot;)&#10;&#10;# Load classifier data&#10;X_train_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_train.parquet'))&#10;X_test_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_test.parquet'))&#10;Y_train = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_train.parquet')).squeeze()&#10;Y_test = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_test.parquet')).squeeze()&#10;&#10;# Try loading validation data if available for leak-proof view&#10;try:&#10;    X_validate_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_validate.parquet'))&#10;    Y_validate = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_validate.parquet')).squeeze()&#10;    # Create trainval set (similar to original notebook's X_trainval_cls)&#10;    X_trainval_cls = pd.concat([X_train_cls, X_validate_cls], axis=0)&#10;    Y_trainval = pd.concat([Y_train, Y_validate], axis=0)&#10;    print(f&quot;Combined train+validation data: {X_trainval_cls.shape}&quot;)&#10;except Exception as e:&#10;    print(f&quot;No validation data found or error loading it: {e}&quot;)&#10;    X_trainval_cls = X_train_cls&#10;    Y_trainval = Y_train&#10;    print(f&quot;Using train data only: {X_trainval_cls.shape}&quot;)&#10;&#10;# Ensure columns names match the classifier's expectation&#10;try:&#10;    if len(selected_cols_cls) == X_trainval_cls.shape[1]:&#10;        X_trainval_cls.columns = selected_cols_cls&#10;        X_test_cls.columns = selected_cols_cls&#10;    else:&#10;        print(f&quot;WARNING: Feature name count mismatch: {len(selected_cols_cls)} names vs {X_trainval_cls.shape[1]} columns&quot;)&#10;except Exception as e:&#10;    print(f&quot;Error setting column names: {e}&quot;)&#10;&#10;# Regressor (secondary target: ap_hi)&#10;reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_final_model.json')&#10;if not os.path.exists(reg_model_path):&#10;    reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_train_model.json')&#10;&#10;reg = xgb.XGBRegressor()&#10;reg.load_model(reg_model_path)&#10;print(f&quot;Loaded regressor from: {reg_model_path}&quot;)&#10;&#10;# Load regressor feature info and data&#10;feature_info_path = os.path.join(REGRESSION_DIR, 'feature_info.pkl')&#10;with open(feature_info_path, 'rb') as f:&#10;    feature_info_reg = joblib.load(f)&#10;&#10;feature_names_reg = feature_info_reg.get('feature_names', [])&#10;X_train_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'X_train.parquet'))&#10;X_test_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'X_test.parquet'))&#10;y_train_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'y_train.parquet')).squeeze()&#10;y_test_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'y_test.parquet')).squeeze()&#10;&#10;# Set column names for regressor data&#10;X_train_reg.columns = feature_names_reg&#10;X_test_reg.columns = feature_names_reg&#10;&#10;print(f&quot;Classification data: X_train={X_train_cls.shape}, X_test={X_test_cls.shape}&quot;)&#10;print(f&quot;Regression data: X_train={X_train_reg.shape}, X_test={X_test_reg.shape}&quot;)&#10;&#10;# --------------------------------------&#10;# 1) A helper to group one-hot features&#10;# --------------------------------------&#10;def parent_name(col: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Map one-hot columns and engineered variants back to a parent feature.&#10;    Examples:&#10;      'cholesterol_3' -&gt; 'cholesterol'&#10;      'gluc_2'        -&gt; 'gluc'&#10;      'gender_2'      -&gt; 'gender'&#10;      'smoke_1'       -&gt; 'smoke'&#10;      'active_1'      -&gt; 'active'&#10;      'bp_category_Normal' -&gt; 'bp_category'&#10;      'bmi' -&gt; 'bmi'&#10;      'pulse_pressure' -&gt; 'pulse_pressure'&#10;    &quot;&quot;&quot;&#10;    # engineered and numeric stay as-is&#10;    engineered = [&#10;        'bmi', 'pulse_pressure', 'mean_bp', 'age_weight_interaction',&#10;        'age_bmi_interaction', 'height_weight_ratio', 'weight_height_interaction',&#10;        'age_smoke_interaction', 'age_alcohol_interaction'&#10;    ]&#10;    if col in engineered:&#10;        return col&#10;&#10;    # strip common one-hot suffixes&#10;    m = re.match(r'^(.*?)(_[-A-Za-z0-9]+)$', col)&#10;    if m:&#10;        return m.group(1)&#10;    # else leave as-is&#10;    return col&#10;&#10;def group_importances(names, values):&#10;    &quot;&quot;&quot;&#10;    Aggregate importance (or |SHAP| means) by parent feature.&#10;    Returns a sorted DataFrame.&#10;    &quot;&quot;&quot;&#10;    df = pd.DataFrame({'feature': names, 'value': values})&#10;    df['parent'] = df['feature'].map(parent_name)&#10;    agg = df.groupby('parent', as_index=False)['value'].sum()&#10;    agg = agg.sort_values('value', ascending=False).reset_index(drop=True)&#10;    return agg&#10;&#10;# --------------------------------------&#10;# 2) SHAP for both models (same protocol)&#10;# --------------------------------------&#10;# Important: use TreeExplainer for tree models; use same sample size and&#10;# background method to make magnitudes more comparable.&#10;&#10;# Sample size for SHAP (speed vs. stability)&#10;N_SHAP = 2000&#10;&#10;# Classifier SHAP on Train+Val (leak-proof view of &quot;what the classifier learned&quot;)&#10;X_shap_cls = X_trainval_cls.sample(min(N_SHAP, len(X_trainval_cls)), random_state=42)&#10;&#10;print(&quot;\nComputing SHAP values for classifier...&quot;)&#10;explainer_cls = shap.TreeExplainer(clf)&#10;shap_vals_cls = explainer_cls(X_shap_cls, check_additivity=False)&#10;print(&quot;Done!&quot;)&#10;&#10;# SHAP importance: mean absolute SHAP per feature&#10;shap_imp_cls = np.abs(shap_vals_cls.values).mean(axis=0)&#10;shap_imp_cls_df = group_importances(X_shap_cls.columns, shap_imp_cls)&#10;shap_imp_cls_df.rename(columns={'value': 'mean_abs_shap_cls'}, inplace=True)&#10;&#10;# Regressor SHAP on its Train set (same size sampling)&#10;X_shap_reg = X_train_reg.sample(min(N_SHAP, len(X_train_reg)), random_state=42)&#10;print(&quot;Computing SHAP values for regressor...&quot;)&#10;explainer_reg = shap.TreeExplainer(reg)&#10;shap_vals_reg = explainer_reg(X_shap_reg, check_additivity=False)&#10;print(&quot;Done!&quot;)&#10;&#10;shap_imp_reg = np.abs(shap_vals_reg.values).mean(axis=0)&#10;shap_imp_reg_df = group_importances(X_shap_reg.columns, shap_imp_reg)&#10;shap_imp_reg_df.rename(columns={'value': 'mean_abs_shap_reg'}, inplace=True)&#10;&#10;# --------------------------------------&#10;# 3) Model-native importances (optional)&#10;# --------------------------------------&#10;# For extra context; not as faithful as SHAP, but quick to compare.&#10;# Classifier&#10;fi_cls = getattr(clf, 'feature_importances_', None)&#10;fi_cls_df = group_importances(X_shap_cls.columns, fi_cls) if fi_cls is not None else None&#10;if fi_cls_df is not None:&#10;    fi_cls_df.rename(columns={'value': 'xgb_importance_cls'}, inplace=True)&#10;&#10;# Regressor&#10;fi_reg = getattr(reg, 'feature_importances_', None)&#10;fi_reg_df = group_importances(X_shap_reg.columns, fi_reg) if fi_reg is not None else None&#10;if fi_reg_df is not None:&#10;    fi_reg_df.rename(columns={'value': 'xgb_importance_reg'}, inplace=True)&#10;&#10;# --------------------------------------&#10;# 4) Join and compute agreement metrics&#10;# --------------------------------------&#10;cmp = pd.merge(shap_imp_cls_df, shap_imp_reg_df, on='parent', how='outer').fillna(0.0)&#10;# Normalize to compare magnitude on the same scale&#10;for col in ['mean_abs_shap_cls', 'mean_abs_shap_reg']:&#10;    s = cmp[col].sum()&#10;    cmp[col] = cmp[col] / s if s &gt; 0 else cmp[col]&#10;&#10;# Ranks&#10;cmp['rank_cls'] = cmp['mean_abs_shap_cls'].rank(ascending=False, method='dense')&#10;cmp['rank_reg'] = cmp['mean_abs_shap_reg'].rank(ascending=False, method='dense')&#10;cmp['rank_diff'] = cmp['rank_reg'] - cmp['rank_cls']&#10;&#10;# Rank correlations across union of parents&#10;rho_s, p_s = spearmanr(cmp['mean_abs_shap_cls'], cmp['mean_abs_shap_reg'])&#10;tau_k, p_k = kendalltau(cmp['mean_abs_shap_cls'], cmp['mean_abs_shap_reg'])&#10;&#10;# Jaccard overlap for Top-K (shared parents in top lists)&#10;K = 10&#10;top_cls = set(cmp.sort_values('mean_abs_shap_cls', ascending=False).head(K)['parent'])&#10;top_reg = set(cmp.sort_values('mean_abs_shap_reg', ascending=False).head(K)['parent'])&#10;jaccard_topK = len(top_cls &amp; top_reg) / max(1, len(top_cls | top_reg))&#10;&#10;print(&quot;\n--- Feature Importance Agreement Metrics ---&quot;)&#10;print(f&quot;Spearman ρ = {rho_s:.3f} (p={p_s:.3g})&quot;)&#10;print(f&quot;Kendall τ = {tau_k:.3f} (p={p_k:.3g})&quot;)&#10;print(f&quot;Top-{K} Jaccard overlap = {jaccard_topK:.2f}&quot;)&#10;&#10;# Save the full comparison table&#10;cmp = cmp.sort_values(['mean_abs_shap_cls', 'mean_abs_shap_reg'], ascending=[False, False])&#10;cmp.to_csv('shap_importance_comparison.csv', index=False)&#10;print(&quot;Saved: shap_importance_comparison.csv&quot;)&#10;&#10;# --------------------------------------&#10;# 5) Visualizations - Feature Importance&#10;# --------------------------------------&#10;&#10;# (A) Scatter: SHAP importance (normalized) across models&#10;plt.figure(figsize=(9, 8))&#10;plt.scatter(cmp['mean_abs_shap_reg'], cmp['mean_abs_shap_cls'], s=50, alpha=0.8)&#10;lim = (0, max(cmp[['mean_abs_shap_reg', 'mean_abs_shap_cls']].max()) * 1.05)&#10;plt.plot([0,1],[0,1], 'r--', alpha=0.6)&#10;plt.xlabel('ap_hi Regressor — normalized mean |SHAP|')&#10;plt.ylabel('CVD Classifier — normalized mean |SHAP|')&#10;plt.title('Feature importance agreement via SHAP (normalized)')&#10;# annotate top disagreements&#10;delta = (cmp['mean_abs_shap_cls'] - cmp['mean_abs_shap_reg']).abs()&#10;for _, r in cmp.sort_values(delta.name, ascending=False).head(10).iterrows():&#10;    plt.annotate(r['parent'], (r['mean_abs_shap_reg'], r['mean_abs_shap_cls']),&#10;                 xytext=(6, 3), textcoords='offset points', fontsize=9)&#10;plt.grid(alpha=0.3)&#10;plt.tight_layout()&#10;plt.savefig('shap_importance_scatter.svg', format='svg', bbox_inches='tight')&#10;plt.savefig('shap_importance_scatter.png', bbox_inches='tight')&#10;plt.show()&#10;print(&quot;Saved: shap_importance_scatter.svg/png&quot;)&#10;&#10;# (B) Dumbbell chart for Top-N parents ranked by classifier&#10;N = 15&#10;show = cmp.sort_values('mean_abs_shap_cls', ascending=False).head(N).copy()&#10;show = show.sort_values('mean_abs_shap_cls', ascending=True)  # for horizontal chart&#10;&#10;plt.figure(figsize=(10, 8))&#10;y = np.arange(len(show))&#10;plt.hlines(y=y, xmin=show['mean_abs_shap_reg'], xmax=show['mean_abs_shap_cls'], colors='gray', alpha=0.7)&#10;plt.scatter(show['mean_abs_shap_reg'], y, color='tab:blue', label='ap_hi regressor')&#10;plt.scatter(show['mean_abs_shap_cls'], y, color='tab:orange', label='CVD classifier')&#10;plt.yticks(y, show['parent'])&#10;plt.xlabel('Normalized mean |SHAP|')&#10;plt.title('SHAP importance: CVD classifier vs. ap_hi regressor (Top by classifier)')&#10;plt.legend()&#10;plt.grid(axis='x', alpha=0.3)&#10;plt.tight_layout()&#10;plt.savefig('shap_dumbbell_top_by_classifier.svg', format='svg', bbox_inches='tight')&#10;plt.savefig('shap_dumbbell_top_by_classifier.png', bbox_inches='tight')&#10;plt.show()&#10;print(&quot;Saved: shap_dumbbell_top_by_classifier.svg/png&quot;)&#10;&#10;&#10;# ============================================&#10;# STEP 4 — Correlate predicted ap_hi with CVD probability&#10;# ============================================&#10;&#10;print(&quot;\n\n&quot; + &quot;=&quot; * 50)&#10;print(&quot;STEP 4 — Correlate predicted ap_hi with CVD probability&quot;)&#10;print(&quot;=&quot; * 50)&#10;&#10;# ----------------------------------------&#10;# 1) Make predictions on the same cohort&#10;# ----------------------------------------&#10;&#10;# Classifier probabilities (P(CVD=1)) on its test set&#10;prob_cardio = clf.predict_proba(X_test_cls)[:, 1]&#10;&#10;# Regressor predictions on its test set&#10;pred_ap_hi = reg.predict(X_test_reg)&#10;&#10;# Attempt to align rows by index/ID if available; otherwise align by position&#10;def best_align(a, b):&#10;    &quot;&quot;&quot;&#10;    Align two arrays/Series by index if both are pandas with equal ordered index.&#10;    Else, align by position with a length check.&#10;    &quot;&quot;&quot;&#10;    if isinstance(a, pd.Series) and isinstance(b, pd.Series):&#10;        if len(a) == len(b) and (a.index.equals(b.index)):&#10;            return a.values, b.values&#10;    # Fallback: position-based&#10;    n = min(len(a), len(b))&#10;    if len(a) != len(b):&#10;        print(f&quot;WARNING: Length mismatch (a={len(a)}, b={len(b)}). &quot;&#10;              f&quot;Falling back to positional alignment on first {n} rows.&quot;)&#10;    return np.asarray(a)[:n], np.asarray(b)[:n]&#10;&#10;prob_cardio_aligned, pred_ap_hi_aligned = best_align(&#10;    pd.Series(prob_cardio), pd.Series(pred_ap_hi)&#10;)&#10;&#10;# If you also want aligned true labels for CVD (for bin prevalence):&#10;Y_test_aligned, _ = best_align(Y_test, pd.Series(pred_ap_hi))&#10;&#10;# Optionally add covariates for partial correlation&#10;covariates_df = pd.DataFrame(index=range(len(prob_cardio_aligned)))&#10;for candidate in ['bmi', 'age_years', 'gender_2', 'cholesterol_2', 'cholesterol_3', 'gluc_2', 'gluc_3']:&#10;    if candidate in X_test_cls.columns:&#10;        covariates_df[candidate] = X_test_cls[candidate].values[:len(covariates_df)]&#10;&#10;# Final analysis frame&#10;df_corr = pd.DataFrame({&#10;    'prob_cardio': prob_cardio_aligned,&#10;    'pred_ap_hi':  pred_ap_hi_aligned,&#10;    'y_cardio':    Y_test_aligned&#10;})&#10;df_corr = pd.concat([df_corr, covariates_df], axis=1)&#10;&#10;print(f&quot;Aligned rows for analysis: {len(df_corr)}&quot;)&#10;&#10;# ----------------------------------------&#10;# 2) Correlation statistics&#10;# ----------------------------------------&#10;pearson_r, pearson_p = pearsonr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;spearman_r, spearman_p = spearmanr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;kendall_t, kendall_p = kendalltau(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;&#10;print(&quot;\nAssociation between predicted systolic BP and CVD probability&quot;)&#10;print(&quot;-------------------------------------------------------------&quot;)&#10;print(f&quot;Pearson r   = {pearson_r:.3f} (p={pearson_p:.3g})&quot;)&#10;print(f&quot;Spearman ρ  = {spearman_r:.3f} (p={spearman_p:.3g})&quot;)&#10;print(f&quot;Kendall τ   = {kendall_t:.3f} (p={kendall_p:.3g})&quot;)&#10;&#10;# ----------------------------------------&#10;# 3) Partial correlation (residual approach)&#10;#    Control for covariates (age, BMI, sex, cholesterol, glucose if available)&#10;# ----------------------------------------&#10;covars = [c for c in ['age_years','bmi','gender_2','cholesterol_2','cholesterol_3','gluc_2','gluc_3']&#10;          if c in df_corr.columns]&#10;&#10;if len(covars) &gt;= 1:&#10;    # Residualize pred_ap_hi on covars&#10;    Xc = df_corr[covars].fillna(df_corr[covars].median())&#10;    lr1 = LinearRegression().fit(Xc, df_corr['pred_ap_hi'])&#10;    res_ap_hi = df_corr['pred_ap_hi'] - lr1.predict(Xc)&#10;&#10;    # Residualize prob_cardio on covars (treat probability as continuous for partial-corr)&#10;    lr2 = LinearRegression().fit(Xc, df_corr['prob_cardio'])&#10;    res_prob = df_corr['prob_cardio'] - lr2.predict(Xc)&#10;&#10;    pr_r, pr_p = pearsonr(res_ap_hi, res_prob)&#10;    print(&quot;\nPartial correlation (controlling for covariates)&quot;)&#10;    print(&quot;------------------------------------------------&quot;)&#10;    print(f&quot;Partial Pearson r = {pr_r:.3f} (p={pr_p:.3g})&quot;)&#10;    print(f&quot;Controlled for: {', '.join(covars)}&quot;)&#10;else:&#10;    print(&quot;\nPartial correlation: skipped (no covariates available in current matrices)&quot;)&#10;&#10;# ----------------------------------------&#10;# 4) Visualizations - Predictions&#10;# ----------------------------------------&#10;&#10;# A) Scatter with LOWESS curve&#10;plt.figure(figsize=(8.5, 7.5))&#10;sns.regplot(x='pred_ap_hi', y='prob_cardio', data=df_corr,&#10;            scatter_kws={'alpha':0.35, 's':20}, lowess=True, line_kws={'color':'red','lw':2})&#10;plt.xlabel('Predicted Systolic BP (mmHg)')&#10;plt.ylabel('Predicted Probability of CVD')&#10;plt.title('Predicted CVD Probability vs Predicted Systolic BP')&#10;plt.grid(alpha=0.3)&#10;plt.tight_layout()&#10;plt.savefig('predBP_vs_probCVD_scatter_lowess.svg', format='svg', bbox_inches='tight')&#10;plt.savefig('predBP_vs_probCVD_scatter_lowess.png', bbox_inches='tight')&#10;plt.show()&#10;&#10;# B) Decile plot: CVD probability &amp; prevalence across ap_hî deciles&#10;df_bins = df_corr.copy()&#10;df_bins['ap_decile'] = pd.qcut(df_bins['pred_ap_hi'], q=10, duplicates='drop')&#10;grouped = df_bins.groupby('ap_decile', observed=True).agg(&#10;    mean_pred_bp=('pred_ap_hi','mean'),&#10;    mean_prob_cvd=('prob_cardio','mean'),&#10;    n=('prob_cardio','size'),&#10;    cvd_prev=('y_cardio','mean')  # requires y_cardio to be 0/1&#10;).reset_index()&#10;&#10;# Sort by mean predicted BP (qcut already sorts by range, but be explicit)&#10;grouped = grouped.sort_values('mean_pred_bp').reset_index(drop=True)&#10;&#10;plt.figure(figsize=(10, 7))&#10;ax = plt.gca()&#10;ax2 = ax.twinx()&#10;&#10;ax.plot(grouped.index+1, grouped['mean_prob_cvd'], color='tab:blue', lw=3, marker='o', label='Mean predicted P(CVD)')&#10;if 'cvd_prev' in grouped and not grouped['cvd_prev'].isna().all():&#10;    ax2.plot(grouped.index+1, grouped['cvd_prev'], color='tab:orange', lw=3, marker='s', label='Observed CVD prevalence')&#10;&#10;ax.set_xlabel('Predicted Systolic BP Decile (lowest → highest)')&#10;ax.set_ylabel('Mean Predicted P(CVD)', color='tab:blue')&#10;ax2.set_ylabel('Observed CVD Prevalence', color='tab:orange')&#10;plt.title('CVD risk across deciles of predicted systolic BP')&#10;ax.grid(alpha=0.3)&#10;lines, labels = ax.get_legend_handles_labels()&#10;lines2, labels2 = ax2.get_legend_handles_labels()&#10;ax2.legend(lines+lines2, labels+labels2, loc='upper left')&#10;plt.tight_layout()&#10;plt.savefig('cvd_vs_predBP_deciles.svg', format='svg', bbox_inches='tight')&#10;plt.savefig('cvd_vs_predBP_deciles.png', bbox_inches='tight')&#10;plt.show()&#10;&#10;# Save the decile table&#10;grouped.to_csv('cvd_vs_predBP_deciles.csv', index=False)&#10;print(&quot;Saved: predBP_vs_probCVD_scatter_lowess.(svg/png) and cvd_vs_predBP_deciles.(svg/png/csv)&quot;)&#10;&#10;# ----------------------------------------&#10;# 5) Optional: quantify incremental value of predicted ap_hi&#10;#    Fit a small logistic model on test set: prob_CVD ~ predicted ap_hi&#10;#    Then compare AUC to the classifier's AUC on the same set&#10;# ----------------------------------------&#10;try:&#10;    # AUC of your classifier on test&#10;    auc_cls = roc_auc_score(df_corr['y_cardio'], df_corr['prob_cardio'])&#10;&#10;    # AUC using only predicted ap_hi&#10;    pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=200))])&#10;    pipe.fit(df_corr[['pred_ap_hi']], df_corr['y_cardio'])&#10;    auc_bp_only = roc_auc_score(df_corr['y_cardio'], pipe.predict_proba(df_corr[['pred_ap_hi']])[:,1])&#10;&#10;    print(&quot;\nIncremental value check (same test cohort)&quot;)&#10;    print(&quot;------------------------------------------&quot;)&#10;    print(f&quot;AUC (full classifier)      : {auc_cls:.3f}&quot;)&#10;    print(f&quot;AUC (predicted ap_hi only) : {auc_bp_only:.3f}&quot;)&#10;    print(f&quot;Difference                 : {auc_cls - auc_bp_only:.3f}&quot;)&#10;    print(&quot;Interpretation: the closer ap_hi-only AUC is to the full model AUC, &quot;&#10;          &quot;the more the classifier's risk signal is mediated through systolic BP.&quot;)&#10;except Exception as e:&#10;    print(f&quot;Incremental value check skipped: {e}&quot;)&#10;&#10;print(&quot;\nModel comparison analysis completed!&quot;)&#10;" />
              <option name="updatedContent" value="# ============================================&#10;# STEP 3 — Compare feature importance + SHAP&#10;# ============================================&#10;import os&#10;import re&#10;import json&#10;import joblib&#10;import numpy as np&#10;import pandas as pd&#10;import shap&#10;import matplotlib.pyplot as plt&#10;import xgboost as xgb&#10;import seaborn as sns&#10;from scipy.stats import spearmanr, kendalltau, pearsonr&#10;import warnings&#10;from sklearn.metrics import roc_auc_score&#10;from sklearn.linear_model import LinearRegression&#10;from sklearn.preprocessing import StandardScaler&#10;from sklearn.pipeline import Pipeline&#10;from sklearn.linear_model import LogisticRegression&#10;&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;plt.rcParams['figure.dpi'] = 200&#10;plt.rcParams['savefig.dpi'] = 300&#10;plt.rcParams['font.size'] = 12&#10;&#10;# Define paths to the Classification and Regression folders&#10;CLASSIFICATION_DIR = './Classification'&#10;REGRESSION_DIR = './Regression'&#10;&#10;print(&quot;Starting model comparison analysis...&quot;)&#10;print(f&quot;Classification directory: {os.path.abspath(CLASSIFICATION_DIR)}&quot;)&#10;print(f&quot;Regression directory: {os.path.abspath(REGRESSION_DIR)}&quot;)&#10;&#10;# -----------------------------&#10;# 0) Load models and data&#10;# -----------------------------&#10;# Classifier (primary target: cardio)&#10;clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_enhanced.pkl')&#10;if not os.path.exists(clf_model_path):&#10;    clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_model.pkl')&#10;&#10;clf = joblib.load(clf_model_path)&#10;print(f&quot;\nLoaded classifier from: {clf_model_path}&quot;)&#10;&#10;# Get expected feature count for classifier&#10;clf_n_features = getattr(clf, 'n_features_in_', None)&#10;if clf_n_features is None:&#10;    # For older XGBoost versions that don't have n_features_in_&#10;    if hasattr(clf, 'get_booster'):&#10;        clf_n_features = clf.get_booster().feature_names&#10;        if clf_n_features:&#10;            clf_n_features = len(clf_n_features)&#10;&#10;print(f&quot;Classifier expects {clf_n_features} features&quot;)&#10;&#10;# Try to load feature names for classifier from feature importance rankings&#10;try:&#10;    feature_rankings_path = os.path.join(CLASSIFICATION_DIR, 'feature_importance_rankings.csv')&#10;    if os.path.exists(feature_rankings_path):&#10;        feature_rankings = pd.read_csv(feature_rankings_path)&#10;        selected_cols_cls = feature_rankings['feature'].tolist()&#10;    else:&#10;        # Fallback: try to reconstruct from model&#10;        selected_cols_cls = [f'clf_feature_{i}' for i in range(clf_n_features)]&#10;    print(f&quot;Loaded {len(selected_cols_cls)} classifier feature names&quot;)&#10;except Exception as e:&#10;    print(f&quot;Warning: Could not load classifier feature names: {e}&quot;)&#10;    selected_cols_cls = [f'clf_feature_{i}' for i in range(clf_n_features or 100)]&#10;&#10;# Load classifier data&#10;X_train_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_train.parquet'))&#10;X_test_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_test.parquet'))&#10;Y_train = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_train.parquet')).squeeze()&#10;Y_test = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_test.parquet')).squeeze()&#10;&#10;print(f&quot;Classifier data shapes: X_train={X_train_cls.shape}, X_test={X_test_cls.shape}&quot;)&#10;&#10;# Ensure feature count matches model expectation&#10;if clf_n_features and X_train_cls.shape[1] != clf_n_features:&#10;    print(f&quot;WARNING: Feature count mismatch! Model expects {clf_n_features} features but data has {X_train_cls.shape[1]} features&quot;)&#10;    # If you have a list of expected feature names, you could select only those or handle this differently&#10;&#10;# Try loading validation data if available for leak-proof view&#10;try:&#10;    X_validate_cls = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'X_validate.parquet'))&#10;    Y_validate = pd.read_parquet(os.path.join(CLASSIFICATION_DIR, 'Y_validate.parquet')).squeeze()&#10;    # Create trainval set (similar to original notebook's X_trainval_cls)&#10;    X_trainval_cls = pd.concat([X_train_cls, X_validate_cls], axis=0)&#10;    Y_trainval = pd.concat([Y_train, Y_validate], axis=0)&#10;    print(f&quot;Combined train+validation data: {X_trainval_cls.shape}&quot;)&#10;except Exception as e:&#10;    print(f&quot;No validation data found or error loading it: {e}&quot;)&#10;    X_trainval_cls = X_train_cls&#10;    Y_trainval = Y_train&#10;    print(f&quot;Using train data only: {X_trainval_cls.shape}&quot;)&#10;&#10;# Ensure columns names are set properly - without overriding if count doesn't match&#10;# We'll use the actual column names if the expected feature count doesn't match&#10;if len(selected_cols_cls) == X_train_cls.shape[1]:&#10;    X_train_cls.columns = selected_cols_cls&#10;    X_test_cls.columns = selected_cols_cls&#10;    X_trainval_cls.columns = selected_cols_cls&#10;else:&#10;    print(f&quot;WARNING: Feature name count mismatch: {len(selected_cols_cls)} names vs {X_train_cls.shape[1]} columns&quot;)&#10;    print(&quot;Using actual column names instead of attempting to rename&quot;)&#10;    # Keep the existing column names&#10;    selected_cols_cls = X_train_cls.columns.tolist()&#10;&#10;# Regressor (secondary target: ap_hi)&#10;reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_final_model.json')&#10;if not os.path.exists(reg_model_path):&#10;    reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_train_model.json')&#10;&#10;reg = xgb.XGBRegressor()&#10;reg.load_model(reg_model_path)&#10;print(f&quot;Loaded regressor from: {reg_model_path}&quot;)&#10;&#10;# Load regressor feature info and data&#10;feature_info_path = os.path.join(REGRESSION_DIR, 'feature_info.pkl')&#10;with open(feature_info_path, 'rb') as f:&#10;    feature_info_reg = joblib.load(f)&#10;&#10;feature_names_reg = feature_info_reg.get('feature_names', [])&#10;X_train_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'X_train.parquet'))&#10;X_test_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'X_test.parquet'))&#10;y_train_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'y_train.parquet')).squeeze()&#10;y_test_reg = pd.read_parquet(os.path.join(REGRESSION_DIR, 'y_test.parquet')).squeeze()&#10;&#10;# Verify the regressor feature count matches the expected count&#10;reg_n_features = getattr(reg, 'n_features_in_', None)&#10;if reg_n_features is None:&#10;    if hasattr(reg, 'get_booster'):&#10;        reg_n_features = reg.get_booster().feature_names&#10;        if reg_n_features:&#10;            reg_n_features = len(reg_n_features)&#10;&#10;print(f&quot;Regressor data shapes: X_train={X_train_reg.shape}, X_test={X_test_reg.shape}&quot;)&#10;print(f&quot;Regressor expects {reg_n_features} features&quot;)&#10;&#10;# Set column names for regressor data only if counts match&#10;if len(feature_names_reg) == X_train_reg.shape[1]:&#10;    X_train_reg.columns = feature_names_reg&#10;    X_test_reg.columns = feature_names_reg&#10;else:&#10;    print(f&quot;WARNING: Feature name count mismatch for regressor: {len(feature_names_reg)} names vs {X_train_reg.shape[1]} columns&quot;)&#10;    print(&quot;Using actual column names instead of attempting to rename&quot;)&#10;    # Keep the existing column names&#10;    feature_names_reg = X_train_reg.columns.tolist()&#10;&#10;print(f&quot;Classification data: X_train={X_train_cls.shape}, X_test={X_test_cls.shape}&quot;)&#10;print(f&quot;Regression data: X_train={X_train_reg.shape}, X_test={X_test_reg.shape}&quot;)&#10;&#10;# --------------------------------------&#10;# 1) A helper to group one-hot features&#10;# --------------------------------------&#10;def parent_name(col: str) -&gt; str:&#10;    &quot;&quot;&quot;&#10;    Map one-hot columns and engineered variants back to a parent feature.&#10;    Examples:&#10;      'cholesterol_3' -&gt; 'cholesterol'&#10;      'gluc_2'        -&gt; 'gluc'&#10;      'gender_2'      -&gt; 'gender'&#10;      'smoke_1'       -&gt; 'smoke'&#10;      'active_1'      -&gt; 'active'&#10;      'bp_category_Normal' -&gt; 'bp_category'&#10;      'bmi' -&gt; 'bmi'&#10;      'pulse_pressure' -&gt; 'pulse_pressure'&#10;    &quot;&quot;&quot;&#10;    # engineered and numeric stay as-is&#10;    engineered = [&#10;        'bmi', 'pulse_pressure', 'mean_bp', 'age_weight_interaction',&#10;        'age_bmi_interaction', 'height_weight_ratio', 'weight_height_interaction',&#10;        'age_smoke_interaction', 'age_alcohol_interaction'&#10;    ]&#10;    if col in engineered:&#10;        return col&#10;&#10;    # strip common one-hot suffixes&#10;    m = re.match(r'^(.*?)(_[-A-Za-z0-9]+)$', col)&#10;    if m:&#10;        return m.group(1)&#10;    # else leave as-is&#10;    return col&#10;&#10;def group_importances(names, values):&#10;    &quot;&quot;&quot;&#10;    Aggregate importance (or |SHAP| means) by parent feature.&#10;    Returns a sorted DataFrame.&#10;    &quot;&quot;&quot;&#10;    df = pd.DataFrame({'feature': names, 'value': values})&#10;    df['parent'] = df['feature'].map(parent_name)&#10;    agg = df.groupby('parent', as_index=False)['value'].sum()&#10;    agg = agg.sort_values('value', ascending=False).reset_index(drop=True)&#10;    return agg&#10;&#10;# --------------------------------------&#10;# 2) SHAP for both models (same protocol)&#10;# --------------------------------------&#10;# Important: use TreeExplainer for tree models; use same sample size and&#10;# background method to make magnitudes more comparable.&#10;&#10;# Sample size for SHAP (speed vs. stability)&#10;N_SHAP = 2000&#10;&#10;print(&quot;\nComputing SHAP values...&quot;)&#10;&#10;try:&#10;    # Classifier SHAP on Train+Val (leak-proof view of &quot;what the classifier learned&quot;)&#10;    X_shap_cls = X_trainval_cls.sample(min(N_SHAP, len(X_trainval_cls)), random_state=42)&#10;    &#10;    print(&quot;Computing SHAP values for classifier...&quot;)&#10;    explainer_cls = shap.TreeExplainer(clf)&#10;    shap_vals_cls = explainer_cls(X_shap_cls, check_additivity=False)&#10;    print(&quot;Done with classifier SHAP!&quot;)&#10;    &#10;    # SHAP importance: mean absolute SHAP per feature&#10;    shap_imp_cls = np.abs(shap_vals_cls.values).mean(axis=0)&#10;    shap_imp_cls_df = group_importances(X_shap_cls.columns, shap_imp_cls)&#10;    shap_imp_cls_df.rename(columns={'value': 'mean_abs_shap_cls'}, inplace=True)&#10;&#10;    # Regressor SHAP on its Train set (same size sampling)&#10;    X_shap_reg = X_train_reg.sample(min(N_SHAP, len(X_train_reg)), random_state=42)&#10;    print(&quot;Computing SHAP values for regressor...&quot;)&#10;    explainer_reg = shap.TreeExplainer(reg)&#10;    shap_vals_reg = explainer_reg(X_shap_reg, check_additivity=False)&#10;    print(&quot;Done with regressor SHAP!&quot;)&#10;    &#10;    shap_imp_reg = np.abs(shap_vals_reg.values).mean(axis=0)&#10;    shap_imp_reg_df = group_importances(X_shap_reg.columns, shap_imp_reg)&#10;    shap_imp_reg_df.rename(columns={'value': 'mean_abs_shap_reg'}, inplace=True)&#10;&#10;    # --------------------------------------&#10;    # 3) Model-native importances (optional)&#10;    # --------------------------------------&#10;    # For extra context; not as faithful as SHAP, but quick to compare.&#10;    # Classifier&#10;    fi_cls = getattr(clf, 'feature_importances_', None)&#10;    fi_cls_df = group_importances(X_shap_cls.columns, fi_cls) if fi_cls is not None else None&#10;    if fi_cls_df is not None:&#10;        fi_cls_df.rename(columns={'value': 'xgb_importance_cls'}, inplace=True)&#10;    &#10;    # Regressor&#10;    fi_reg = getattr(reg, 'feature_importances_', None)&#10;    fi_reg_df = group_importances(X_shap_reg.columns, fi_reg) if fi_reg is not None else None&#10;    if fi_reg_df is not None:&#10;        fi_reg_df.rename(columns={'value': 'xgb_importance_reg'}, inplace=True)&#10;    &#10;    # --------------------------------------&#10;    # 4) Join and compute agreement metrics&#10;    # --------------------------------------&#10;    cmp = pd.merge(shap_imp_cls_df, shap_imp_reg_df, on='parent', how='outer').fillna(0.0)&#10;    # Normalize to compare magnitude on the same scale&#10;    for col in ['mean_abs_shap_cls', 'mean_abs_shap_reg']:&#10;        s = cmp[col].sum()&#10;        cmp[col] = cmp[col] / s if s &gt; 0 else cmp[col]&#10;    &#10;    # Ranks&#10;    cmp['rank_cls'] = cmp['mean_abs_shap_cls'].rank(ascending=False, method='dense')&#10;    cmp['rank_reg'] = cmp['mean_abs_shap_reg'].rank(ascending=False, method='dense')&#10;    cmp['rank_diff'] = cmp['rank_reg'] - cmp['rank_cls']&#10;    &#10;    # Rank correlations across union of parents&#10;    rho_s, p_s = spearmanr(cmp['mean_abs_shap_cls'], cmp['mean_abs_shap_reg'])&#10;    tau_k, p_k = kendalltau(cmp['mean_abs_shap_cls'], cmp['mean_abs_shap_reg'])&#10;    &#10;    # Jaccard overlap for Top-K (shared parents in top lists)&#10;    K = 10&#10;    top_cls = set(cmp.sort_values('mean_abs_shap_cls', ascending=False).head(K)['parent'])&#10;    top_reg = set(cmp.sort_values('mean_abs_shap_reg', ascending=False).head(K)['parent'])&#10;    jaccard_topK = len(top_cls &amp; top_reg) / max(1, len(top_cls | top_reg))&#10;    &#10;    print(&quot;\n--- Feature Importance Agreement Metrics ---&quot;)&#10;    print(f&quot;Spearman ρ = {rho_s:.3f} (p={p_s:.3g})&quot;)&#10;    print(f&quot;Kendall τ = {tau_k:.3f} (p={p_k:.3g})&quot;)&#10;    print(f&quot;Top-{K} Jaccard overlap = {jaccard_topK:.2f}&quot;)&#10;    &#10;    # Save the full comparison table&#10;    cmp = cmp.sort_values(['mean_abs_shap_cls', 'mean_abs_shap_reg'], ascending=[False, False])&#10;    cmp.to_csv('shap_importance_comparison.csv', index=False)&#10;    print(&quot;Saved: shap_importance_comparison.csv&quot;)&#10;    &#10;    # --------------------------------------&#10;    # 5) Visualizations - Feature Importance&#10;    # --------------------------------------&#10;    &#10;    # (A) Scatter: SHAP importance (normalized) across models&#10;    plt.figure(figsize=(9, 8))&#10;    plt.scatter(cmp['mean_abs_shap_reg'], cmp['mean_abs_shap_cls'], s=50, alpha=0.8)&#10;    lim = (0, max(cmp[['mean_abs_shap_reg', 'mean_abs_shap_cls']].max()) * 1.05)&#10;    plt.plot([0,1],[0,1], 'r--', alpha=0.6)&#10;    plt.xlabel('ap_hi Regressor — normalized mean |SHAP|')&#10;    plt.ylabel('CVD Classifier — normalized mean |SHAP|')&#10;    plt.title('Feature importance agreement via SHAP (normalized)')&#10;    # annotate top disagreements&#10;    delta = (cmp['mean_abs_shap_cls'] - cmp['mean_abs_shap_reg']).abs()&#10;    for _, r in cmp.sort_values(delta.name, ascending=False).head(10).iterrows():&#10;        plt.annotate(r['parent'], (r['mean_abs_shap_reg'], r['mean_abs_shap_cls']),&#10;                     xytext=(6, 3), textcoords='offset points', fontsize=9)&#10;    plt.grid(alpha=0.3)&#10;    plt.tight_layout()&#10;    plt.savefig('shap_importance_scatter.svg', format='svg', bbox_inches='tight')&#10;    plt.savefig('shap_importance_scatter.png', bbox_inches='tight')&#10;    plt.show()&#10;    print(&quot;Saved: shap_importance_scatter.svg/png&quot;)&#10;    &#10;    # (B) Dumbbell chart for Top-N parents ranked by classifier&#10;    N = 15&#10;    show = cmp.sort_values('mean_abs_shap_cls', ascending=False).head(N).copy()&#10;    show = show.sort_values('mean_abs_shap_cls', ascending=True)  # for horizontal chart&#10;    &#10;    plt.figure(figsize=(10, 8))&#10;    y = np.arange(len(show))&#10;    plt.hlines(y=y, xmin=show['mean_abs_shap_reg'], xmax=show['mean_abs_shap_cls'], colors='gray', alpha=0.7)&#10;    plt.scatter(show['mean_abs_shap_reg'], y, color='tab:blue', label='ap_hi regressor')&#10;    plt.scatter(show['mean_abs_shap_cls'], y, color='tab:orange', label='CVD classifier')&#10;    plt.yticks(y, show['parent'])&#10;    plt.xlabel('Normalized mean |SHAP|')&#10;    plt.title('SHAP importance: CVD classifier vs. ap_hi regressor (Top by classifier)')&#10;    plt.legend()&#10;    plt.grid(axis='x', alpha=0.3)&#10;    plt.tight_layout()&#10;    plt.savefig('shap_dumbbell_top_by_classifier.svg', format='svg', bbox_inches='tight')&#10;    plt.savefig('shap_dumbbell_top_by_classifier.png', bbox_inches='tight')&#10;    plt.show()&#10;    print(&quot;Saved: shap_dumbbell_top_by_classifier.svg/png&quot;)&#10;    &#10;except Exception as e:&#10;    print(f&quot;ERROR during SHAP analysis: {str(e)}&quot;)&#10;    print(&quot;Skipping SHAP analysis due to error and continuing with prediction correlation analysis...&quot;)&#10;&#10;# ============================================&#10;# STEP 4 — Correlate predicted ap_hi with CVD probability&#10;# ============================================&#10;&#10;print(&quot;\n\n&quot; + &quot;=&quot; * 50)&#10;print(&quot;STEP 4 — Correlate predicted ap_hi with CVD probability&quot;)&#10;print(&quot;=&quot; * 50)&#10;&#10;try:&#10;    # ----------------------------------------&#10;    # 1) Make predictions on the same cohort&#10;    # ----------------------------------------&#10;    &#10;    # Classifier probabilities (P(CVD=1)) on its test set&#10;    print(&quot;Making predictions with classifier...&quot;)&#10;    prob_cardio = clf.predict_proba(X_test_cls)[:, 1]&#10;    print(f&quot;Generated {len(prob_cardio)} classifier predictions&quot;)&#10;    &#10;    # Regressor predictions on its test set&#10;    print(&quot;Making predictions with regressor...&quot;)&#10;    pred_ap_hi = reg.predict(X_test_reg)&#10;    print(f&quot;Generated {len(pred_ap_hi)} regressor predictions&quot;)&#10;    &#10;    # Attempt to align rows by index/ID if available; otherwise align by position&#10;    def best_align(a, b):&#10;        &quot;&quot;&quot;&#10;        Align two arrays/Series by index if both are pandas with equal ordered index.&#10;        Else, align by position with a length check.&#10;        &quot;&quot;&quot;&#10;        if isinstance(a, pd.Series) and isinstance(b, pd.Series):&#10;            if len(a) == len(b) and (a.index.equals(b.index)):&#10;                return a.values, b.values&#10;        # Fallback: position-based&#10;        n = min(len(a), len(b))&#10;        if len(a) != len(b):&#10;            print(f&quot;WARNING: Length mismatch (a={len(a)}, b={len(b)}). &quot;&#10;                  f&quot;Falling back to positional alignment on first {n} rows.&quot;)&#10;        return np.asarray(a)[:n], np.asarray(b)[:n]&#10;    &#10;    prob_cardio_aligned, pred_ap_hi_aligned = best_align(&#10;        pd.Series(prob_cardio), pd.Series(pred_ap_hi)&#10;    )&#10;    &#10;    # If you also want aligned true labels for CVD (for bin prevalence):&#10;    Y_test_aligned, _ = best_align(Y_test, pd.Series(pred_ap_hi))&#10;    &#10;    # Optionally add covariates for partial correlation&#10;    covariates_df = pd.DataFrame(index=range(len(prob_cardio_aligned)))&#10;    for candidate in ['bmi', 'age_years', 'gender_2', 'cholesterol_2', 'cholesterol_3', 'gluc_2', 'gluc_3']:&#10;        if candidate in X_test_cls.columns:&#10;            covariates_df[candidate] = X_test_cls[candidate].values[:len(covariates_df)]&#10;    &#10;    # Final analysis frame&#10;    df_corr = pd.DataFrame({&#10;        'prob_cardio': prob_cardio_aligned,&#10;        'pred_ap_hi':  pred_ap_hi_aligned,&#10;        'y_cardio':    Y_test_aligned&#10;    })&#10;    df_corr = pd.concat([df_corr, covariates_df], axis=1)&#10;    &#10;    print(f&quot;Aligned rows for analysis: {len(df_corr)}&quot;)&#10;    &#10;    # ----------------------------------------&#10;    # 2) Correlation statistics&#10;    # ----------------------------------------&#10;    pearson_r, pearson_p = pearsonr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;    spearman_r, spearman_p = spearmanr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;    kendall_t, kendall_p = kendalltau(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;    &#10;    print(&quot;\nAssociation between predicted systolic BP and CVD probability&quot;)&#10;    print(&quot;-------------------------------------------------------------&quot;)&#10;    print(f&quot;Pearson r   = {pearson_r:.3f} (p={pearson_p:.3g})&quot;)&#10;    print(f&quot;Spearman ρ  = {spearman_r:.3f} (p={spearman_p:.3g})&quot;)&#10;    print(f&quot;Kendall τ   = {kendall_t:.3f} (p={kendall_p:.3g})&quot;)&#10;    &#10;    # ----------------------------------------&#10;    # 3) Partial correlation (residual approach)&#10;    #    Control for covariates (age, BMI, sex, cholesterol, glucose if available)&#10;    # ----------------------------------------&#10;    covars = [c for c in ['age_years','bmi','gender_2','cholesterol_2','cholesterol_3','gluc_2','gluc_3']&#10;              if c in df_corr.columns]&#10;    &#10;    if len(covars) &gt;= 1:&#10;        # Residualize pred_ap_hi on covars&#10;        Xc = df_corr[covars].fillna(df_corr[covars].median())&#10;        lr1 = LinearRegression().fit(Xc, df_corr['pred_ap_hi'])&#10;        res_ap_hi = df_corr['pred_ap_hi'] - lr1.predict(Xc)&#10;    &#10;        # Residualize prob_cardio on covars (treat probability as continuous for partial-corr)&#10;        lr2 = LinearRegression().fit(Xc, df_corr['prob_cardio'])&#10;        res_prob = df_corr['prob_cardio'] - lr2.predict(Xc)&#10;    &#10;        pr_r, pr_p = pearsonr(res_ap_hi, res_prob)&#10;        print(&quot;\nPartial correlation (controlling for covariates)&quot;)&#10;        print(&quot;------------------------------------------------&quot;)&#10;        print(f&quot;Partial Pearson r = {pr_r:.3f} (p={pr_p:.3g})&quot;)&#10;        print(f&quot;Controlled for: {', '.join(covars)}&quot;)&#10;    else:&#10;        print(&quot;\nPartial correlation: skipped (no covariates available in current matrices)&quot;)&#10;    &#10;    # ----------------------------------------&#10;    # 4) Visualizations - Predictions&#10;    # ----------------------------------------&#10;    &#10;    # A) Scatter with LOWESS curve&#10;    plt.figure(figsize=(8.5, 7.5))&#10;    sns.regplot(x='pred_ap_hi', y='prob_cardio', data=df_corr,&#10;                scatter_kws={'alpha':0.35, 's':20}, lowess=True, line_kws={'color':'red','lw':2})&#10;    plt.xlabel('Predicted Systolic BP (mmHg)')&#10;    plt.ylabel('Predicted Probability of CVD')&#10;    plt.title('Predicted CVD Probability vs Predicted Systolic BP')&#10;    plt.grid(alpha=0.3)&#10;    plt.tight_layout()&#10;    plt.savefig('predBP_vs_probCVD_scatter_lowess.svg', format='svg', bbox_inches='tight')&#10;    plt.savefig('predBP_vs_probCVD_scatter_lowess.png', bbox_inches='tight')&#10;    plt.show()&#10;    &#10;    # B) Decile plot: CVD probability &amp; prevalence across ap_hî deciles&#10;    df_bins = df_corr.copy()&#10;    df_bins['ap_decile'] = pd.qcut(df_bins['pred_ap_hi'], q=10, duplicates='drop')&#10;    grouped = df_bins.groupby('ap_decile', observed=True).agg(&#10;        mean_pred_bp=('pred_ap_hi','mean'),&#10;        mean_prob_cvd=('prob_cardio','mean'),&#10;        n=('prob_cardio','size'),&#10;        cvd_prev=('y_cardio','mean')  # requires y_cardio to be 0/1&#10;    ).reset_index()&#10;    &#10;    # Sort by mean predicted BP (qcut already sorts by range, but be explicit)&#10;    grouped = grouped.sort_values('mean_pred_bp').reset_index(drop=True)&#10;    &#10;    plt.figure(figsize=(10, 7))&#10;    ax = plt.gca()&#10;    ax2 = ax.twinx()&#10;    &#10;    ax.plot(grouped.index+1, grouped['mean_prob_cvd'], color='tab:blue', lw=3, marker='o', label='Mean predicted P(CVD)')&#10;    if 'cvd_prev' in grouped and not grouped['cvd_prev'].isna().all():&#10;        ax2.plot(grouped.index+1, grouped['cvd_prev'], color='tab:orange', lw=3, marker='s', label='Observed CVD prevalence')&#10;    &#10;    ax.set_xlabel('Predicted Systolic BP Decile (lowest → highest)')&#10;    ax.set_ylabel('Mean Predicted P(CVD)', color='tab:blue')&#10;    ax2.set_ylabel('Observed CVD Prevalence', color='tab:orange')&#10;    plt.title('CVD risk across deciles of predicted systolic BP')&#10;    ax.grid(alpha=0.3)&#10;    lines, labels = ax.get_legend_handles_labels()&#10;    lines2, labels2 = ax2.get_legend_handles_labels()&#10;    ax2.legend(lines+lines2, labels+labels2, loc='upper left')&#10;    plt.tight_layout()&#10;    plt.savefig('cvd_vs_predBP_deciles.svg', format='svg', bbox_inches='tight')&#10;    plt.savefig('cvd_vs_predBP_deciles.png', bbox_inches='tight')&#10;    plt.show()&#10;    &#10;    # Save the decile table&#10;    grouped.to_csv('cvd_vs_predBP_deciles.csv', index=False)&#10;    print(&quot;Saved: predBP_vs_probCVD_scatter_lowess.(svg/png) and cvd_vs_predBP_deciles.(svg/png/csv)&quot;)&#10;    &#10;    # ----------------------------------------&#10;    # 5) Optional: quantify incremental value of predicted ap_hi&#10;    #    Fit a small logistic model on test set: prob_CVD ~ predicted ap_hi&#10;    #    Then compare AUC to the classifier's AUC on the same set&#10;    # ----------------------------------------&#10;    try:&#10;        # AUC of your classifier on test&#10;        auc_cls = roc_auc_score(df_corr['y_cardio'], df_corr['prob_cardio'])&#10;    &#10;        # AUC using only predicted ap_hi&#10;        pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=200))])&#10;        pipe.fit(df_corr[['pred_ap_hi']], df_corr['y_cardio'])&#10;        auc_bp_only = roc_auc_score(df_corr['y_cardio'], pipe.predict_proba(df_corr[['pred_ap_hi']])[:,1])&#10;    &#10;        print(&quot;\nIncremental value check (same test cohort)&quot;)&#10;        print(&quot;------------------------------------------&quot;)&#10;        print(f&quot;AUC (full classifier)      : {auc_cls:.3f}&quot;)&#10;        print(f&quot;AUC (predicted ap_hi only) : {auc_bp_only:.3f}&quot;)&#10;        print(f&quot;Difference                 : {auc_cls - auc_bp_only:.3f}&quot;)&#10;        print(&quot;Interpretation: the closer ap_hi-only AUC is to the full model AUC, &quot;&#10;              &quot;the more the classifier's risk signal is mediated through systolic BP.&quot;)&#10;    except Exception as e:&#10;        print(f&quot;Incremental value check skipped: {e}&quot;)&#10;&#10;except Exception as e:&#10;    print(f&quot;ERROR during prediction correlation analysis: {str(e)}&quot;)&#10;    print(&quot;Analysis could not be completed due to errors&quot;)&#10;&#10;print(&quot;\nModel comparison analysis completed!&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/prediction_correlation.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/prediction_correlation.py" />
              <option name="originalContent" value="# ============================================&#10;# STEP 4 — Correlate predicted ap_hi with CVD probability&#10;# ============================================&#10;import os&#10;import json&#10;import joblib&#10;import warnings&#10;import numpy as np&#10;import pandas as pd&#10;import xgboost as xgb&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;&#10;from sklearn.metrics import (&#10;    precision_recall_curve, average_precision_score,&#10;    roc_auc_score&#10;)&#10;from sklearn.linear_model import LinearRegression&#10;from scipy.stats import pearsonr, spearmanr, kendalltau&#10;&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;plt.rcParams['figure.dpi'] = 200&#10;plt.rcParams['savefig.dpi'] = 300&#10;plt.rcParams['font.size'] = 12&#10;&#10;# Define paths to the Classification and Regression folders&#10;CLASSIFICATION_DIR = './Classification'&#10;REGRESSION_DIR = './Regression'&#10;OUTPUT_DIR = './'  # Save outputs to current directory&#10;&#10;print(&quot;Starting prediction correlation analysis...&quot;)&#10;print(f&quot;Classification directory: {os.path.abspath(CLASSIFICATION_DIR)}&quot;)&#10;print(f&quot;Regression directory: {os.path.abspath(REGRESSION_DIR)}&quot;)&#10;&#10;# -----------------------------&#10;# 0) Load artifacts &amp; data&#10;# -----------------------------&#10;&#10;# Classifier (primary: CVD)&#10;clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_enhanced.pkl')&#10;if not os.path.exists(clf_model_path):&#10;    clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_model.pkl')&#10;&#10;clf = joblib.load(clf_model_path)&#10;print(f&quot;Loaded classifier from: {clf_model_path}&quot;)&#10;&#10;# Load test data for classifier&#10;X_test_cls_path = os.path.join(CLASSIFICATION_DIR, 'X_test.parquet')&#10;Y_test_path = os.path.join(CLASSIFICATION_DIR, 'Y_test.parquet')&#10;&#10;X_test_cls = pd.read_parquet(X_test_cls_path)&#10;Y_test = pd.read_parquet(Y_test_path).squeeze()&#10;print(f&quot;Loaded classifier test data: X_test={X_test_cls.shape}, Y_test={Y_test.shape}&quot;)&#10;&#10;# Regressor (secondary: ap_hi)&#10;reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_final_model.json')&#10;if not os.path.exists(reg_model_path):&#10;    reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_train_model.json')&#10;&#10;reg = xgb.XGBRegressor()&#10;reg.load_model(reg_model_path)&#10;print(f&quot;Loaded regressor from: {reg_model_path}&quot;)&#10;&#10;# Regressor feature info + test matrices&#10;feature_info_path = os.path.join(REGRESSION_DIR, 'feature_info.pkl')&#10;with open(feature_info_path, 'rb') as f:&#10;    feature_info_reg = joblib.load(f) if 'joblib.' in joblib.__name__ else __import__('pickle').load(f)&#10;&#10;feature_names_reg = feature_info_reg['feature_names']&#10;X_test_reg_path = os.path.join(REGRESSION_DIR, 'X_test.parquet')&#10;X_test_reg = pd.read_parquet(X_test_reg_path)&#10;&#10;# Check if model has feature names that are different from our expected ones&#10;model_feature_names = None&#10;if hasattr(reg, 'get_booster') and hasattr(reg.get_booster(), 'feature_names'):&#10;    model_feature_names = reg.get_booster().feature_names&#10;    print(f&quot;Regressor model uses these feature names: {model_feature_names[:5]}... (showing first 5)&quot;)&#10;&#10;# If model expects generic feature names like 'feature_0', adapt our dataframe&#10;if model_feature_names and model_feature_names[0].startswith('feature_'):&#10;    # Create a mapping of original columns to 'feature_X' format&#10;    generic_names = [f'feature_{i}' for i in range(len(X_test_reg.columns))]&#10;    X_test_reg_generic = X_test_reg.copy()&#10;    X_test_reg_generic.columns = generic_names&#10;    print(&quot;Using generic feature names for regressor prediction&quot;)&#10;    # Use this version for prediction&#10;    X_test_reg_for_prediction = X_test_reg_generic&#10;else:&#10;    # Use original column names&#10;    X_test_reg.columns = feature_names_reg&#10;    X_test_reg_for_prediction = X_test_reg&#10;&#10;# Optional: ap_hi ground truth (for decile prevalence plots)&#10;y_test_aphi_path = os.path.join(REGRESSION_DIR, 'y_test.parquet')&#10;y_test_aphi = None&#10;if os.path.exists(y_test_aphi_path):&#10;    y_test_aphi = pd.read_parquet(y_test_aphi_path).squeeze()  # ap_hi true values&#10;    print(f&quot;Loaded ap_hi ground truth: {y_test_aphi.shape}&quot;)&#10;&#10;# ----------------------------------------&#10;# 1) Make predictions on the same cohort&#10;# ----------------------------------------&#10;print(&quot;\nGenerating predictions...&quot;)&#10;&#10;# Classifier probabilities (P(CVD=1)) on its test set&#10;try:&#10;    prob_cardio = clf.predict_proba(X_test_cls)[:, 1]&#10;    print(f&quot;Generated {len(prob_cardio)} classifier predictions&quot;)&#10;except Exception as e:&#10;    print(f&quot;Warning: Error making classifier predictions: {e}&quot;)&#10;    print(&quot;Training a simple model on test data for demonstration...&quot;)&#10;    from sklearn.ensemble import RandomForestClassifier&#10;    simple_clf = RandomForestClassifier(n_estimators=50, random_state=42)&#10;    simple_clf.fit(X_test_cls, Y_test)&#10;    prob_cardio = simple_clf.predict_proba(X_test_cls)[:, 1]&#10;    print(f&quot;Generated {len(prob_cardio)} classifier predictions using simple model&quot;)&#10;&#10;# Regressor predictions on its test set&#10;pred_ap_hi = reg.predict(X_test_reg_for_prediction)&#10;print(f&quot;Generated {len(pred_ap_hi)} regressor predictions&quot;)&#10;&#10;# Attempt to align rows by index/ID if available; otherwise align by position&#10;def best_align(a, b):&#10;    &quot;&quot;&quot;&#10;    Align two arrays/Series by index if both are pandas with equal ordered index.&#10;    Else, align by position with a length check.&#10;    &quot;&quot;&quot;&#10;    if isinstance(a, pd.Series) and isinstance(b, pd.Series):&#10;        if len(a) == len(b) and (a.index.equals(b.index)):&#10;            return a.values, b.values&#10;    # Fallback: position-based&#10;    n = min(len(a), len(b))&#10;    if len(a) != len(b):&#10;        print(f&quot;WARNING: Length mismatch (a={len(a)}, b={len(b)}). &quot;&#10;              f&quot;Falling back to positional alignment on first {n} rows.&quot;)&#10;    return np.asarray(a)[:n], np.asarray(b)[:n]&#10;&#10;prob_cardio_aligned, pred_ap_hi_aligned = best_align(&#10;    pd.Series(prob_cardio), pd.Series(pred_ap_hi)&#10;)&#10;&#10;# If you also want aligned true labels for CVD (for bin prevalence):&#10;Y_test_aligned, _ = best_align(Y_test, pd.Series(pred_ap_hi))&#10;&#10;# Optionally add covariates for partial correlation&#10;covariates_df = pd.DataFrame(index=range(len(prob_cardio_aligned)))&#10;for candidate in ['bmi', 'age_years', 'gender_2', 'cholesterol_2', 'cholesterol_3', 'gluc_2', 'gluc_3']:&#10;    if candidate in X_test_cls.columns:&#10;        covariates_df[candidate] = X_test_cls[candidate].values[:len(covariates_df)]&#10;&#10;# Final analysis frame&#10;df_corr = pd.DataFrame({&#10;    'prob_cardio': prob_cardio_aligned,&#10;    'pred_ap_hi':  pred_ap_hi_aligned,&#10;    'y_cardio':    Y_test_aligned&#10;})&#10;df_corr = pd.concat([df_corr, covariates_df], axis=1)&#10;&#10;print(f&quot;Aligned rows for analysis: {len(df_corr)}&quot;)&#10;&#10;# ----------------------------------------&#10;# 2) Correlation statistics&#10;# ----------------------------------------&#10;pearson_r, pearson_p = pearsonr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;spearman_r, spearman_p = spearmanr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;kendall_t, kendall_p = kendalltau(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;&#10;print(&quot;\nAssociation between predicted systolic BP and CVD probability&quot;)&#10;print(&quot;-------------------------------------------------------------&quot;)&#10;print(f&quot;Pearson r   = {pearson_r:.3f} (p={pearson_p:.3g})&quot;)&#10;print(f&quot;Spearman ρ  = {spearman_r:.3f} (p={spearman_p:.3g})&quot;)&#10;print(f&quot;Kendall τ   = {kendall_t:.3f} (p={kendall_p:.3g})&quot;)&#10;&#10;# ----------------------------------------&#10;# 3) Partial correlation (residual approach)&#10;#    Control for covariates (age, BMI, sex, cholesterol, glucose if available)&#10;# ----------------------------------------&#10;covars = [c for c in ['age_years','bmi','gender_2','cholesterol_2','cholesterol_3','gluc_2','gluc_3']&#10;          if c in df_corr.columns]&#10;&#10;if len(covars) &gt;= 1:&#10;    # Residualize pred_ap_hi on covars&#10;    Xc = df_corr[covars].fillna(df_corr[covars].median())&#10;    lr1 = LinearRegression().fit(Xc, df_corr['pred_ap_hi'])&#10;    res_ap_hi = df_corr['pred_ap_hi'] - lr1.predict(Xc)&#10;&#10;    # Residualize prob_cardio on covars (treat probability as continuous for partial-corr)&#10;    lr2 = LinearRegression().fit(Xc, df_corr['prob_cardio'])&#10;    res_prob = df_corr['prob_cardio'] - lr2.predict(Xc)&#10;&#10;    pr_r, pr_p = pearsonr(res_ap_hi, res_prob)&#10;    print(&quot;\nPartial correlation (controlling for covariates)&quot;)&#10;    print(&quot;------------------------------------------------&quot;)&#10;    print(f&quot;Partial Pearson r = {pr_r:.3f} (p={pr_p:.3g})&quot;)&#10;    print(f&quot;Controlled for: {', '.join(covars)}&quot;)&#10;else:&#10;    print(&quot;\nPartial correlation: skipped (no covariates available in current matrices)&quot;)&#10;&#10;# ----------------------------------------&#10;# 4) Visualizations&#10;# ----------------------------------------&#10;print(&quot;\nCreating visualizations...&quot;)&#10;&#10;# A) Scatter with LOWESS curve&#10;plt.figure(figsize=(8.5, 7.5))&#10;sns.regplot(x='pred_ap_hi', y='prob_cardio', data=df_corr,&#10;            scatter_kws={'alpha':0.35, 's':20}, lowess=True, line_kws={'color':'red','lw':2})&#10;plt.xlabel('Predicted Systolic BP (mmHg)')&#10;plt.ylabel('Predicted Probability of CVD')&#10;plt.title('Predicted CVD Probability vs Predicted Systolic BP')&#10;plt.grid(alpha=0.3)&#10;plt.tight_layout()&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'predBP_vs_probCVD_scatter_lowess.svg'), format='svg', bbox_inches='tight')&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'predBP_vs_probCVD_scatter_lowess.png'), bbox_inches='tight')&#10;plt.show()&#10;&#10;# B) Decile plot: CVD probability &amp; prevalence across ap_hi deciles&#10;df_bins = df_corr.copy()&#10;df_bins['ap_decile'] = pd.qcut(df_bins['pred_ap_hi'], q=10, duplicates='drop')&#10;grouped = df_bins.groupby('ap_decile', observed=True).agg(&#10;    mean_pred_bp=('pred_ap_hi','mean'),&#10;    mean_prob_cvd=('prob_cardio','mean'),&#10;    n=('prob_cardio','size'),&#10;    cvd_prev=('y_cardio','mean')  # requires y_cardio to be 0/1&#10;).reset_index()&#10;&#10;# Sort by mean predicted BP (qcut already sorts by range, but be explicit)&#10;grouped = grouped.sort_values('mean_pred_bp').reset_index(drop=True)&#10;&#10;plt.figure(figsize=(10, 7))&#10;ax = plt.gca()&#10;ax2 = ax.twinx()&#10;&#10;ax.plot(grouped.index+1, grouped['mean_prob_cvd'], color='tab:blue', lw=3, marker='o', label='Mean predicted P(CVD)')&#10;if 'cvd_prev' in grouped and not grouped['cvd_prev'].isna().all():&#10;    ax2.plot(grouped.index+1, grouped['cvd_prev'], color='tab:orange', lw=3, marker='s', label='Observed CVD prevalence')&#10;&#10;ax.set_xlabel('Predicted Systolic BP Decile (lowest → highest)')&#10;ax.set_ylabel('Mean Predicted P(CVD)', color='tab:blue')&#10;ax2.set_ylabel('Observed CVD Prevalence', color='tab:orange')&#10;plt.title('CVD risk across deciles of predicted systolic BP')&#10;ax.grid(alpha=0.3)&#10;lines, labels = ax.get_legend_handles_labels()&#10;lines2, labels2 = ax2.get_legend_handles_labels()&#10;ax2.legend(lines+lines2, labels+labels2, loc='upper left')&#10;plt.tight_layout()&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.svg'), format='svg', bbox_inches='tight')&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.png'), bbox_inches='tight')&#10;plt.show()&#10;&#10;# Save the decile table&#10;grouped.to_csv(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.csv'), index=False)&#10;print(&quot;Saved: predBP_vs_probCVD_scatter_lowess.(svg/png) and cvd_vs_predBP_deciles.(svg/png/csv)&quot;)&#10;&#10;# ----------------------------------------&#10;# 5) Optional: quantify incremental value of predicted ap_hi&#10;#    Fit a small logistic model on test set: prob_CVD ~ predicted ap_hi&#10;#    Then compare AUC to the classifier's AUC on the same set&#10;# ----------------------------------------&#10;try:&#10;    from sklearn.linear_model import LogisticRegression&#10;    from sklearn.preprocessing import StandardScaler&#10;    from sklearn.pipeline import Pipeline&#10;&#10;    # AUC of your classifier on test&#10;    auc_cls = roc_auc_score(df_corr['y_cardio'], df_corr['prob_cardio'])&#10;&#10;    # AUC using only predicted ap_hi&#10;    pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=200))])&#10;    pipe.fit(df_corr[['pred_ap_hi']], df_corr['y_cardio'])&#10;    auc_bp_only = roc_auc_score(df_corr['y_cardio'], pipe.predict_proba(df_corr[['pred_ap_hi']])[:,1])&#10;&#10;    print(&quot;\nIncremental value check (same test cohort)&quot;)&#10;    print(&quot;------------------------------------------&quot;)&#10;    print(f&quot;AUC (full classifier)      : {auc_cls:.3f}&quot;)&#10;    print(f&quot;AUC (predicted ap_hi only) : {auc_bp_only:.3f}&quot;)&#10;    print(f&quot;Difference                 : {auc_cls - auc_bp_only:.3f}&quot;)&#10;    print(&quot;Interpretation: the closer ap_hi-only AUC is to the full model AUC, &quot;&#10;          &quot;the more the classifier's risk signal is mediated through systolic BP.&quot;)&#10;except Exception as e:&#10;    print(f&quot;Incremental value check skipped: {e}&quot;)&#10;&#10;print(&quot;\nPrediction correlation analysis completed!&quot;)&#10;" />
              <option name="updatedContent" value="# ============================================&#10;# STEP 4 — Correlate predicted ap_hi with CVD probability&#10;# ============================================&#10;import os&#10;import json&#10;import joblib&#10;import warnings&#10;import numpy as np&#10;import pandas as pd&#10;import xgboost as xgb&#10;import matplotlib.pyplot as plt&#10;import seaborn as sns&#10;&#10;from sklearn.metrics import (&#10;    precision_recall_curve, average_precision_score,&#10;    roc_auc_score&#10;)&#10;from sklearn.linear_model import LinearRegression&#10;from scipy.stats import pearsonr, spearmanr, kendalltau&#10;&#10;warnings.filterwarnings('ignore')&#10;plt.style.use('seaborn-v0_8')&#10;plt.rcParams['figure.dpi'] = 200&#10;plt.rcParams['savefig.dpi'] = 300&#10;plt.rcParams['font.size'] = 12&#10;&#10;# Define paths to the Classification and Regression folders&#10;CLASSIFICATION_DIR = './Classification'&#10;REGRESSION_DIR = './Regression'&#10;OUTPUT_DIR = './'  # Save outputs to current directory&#10;&#10;print(&quot;Starting prediction correlation analysis...&quot;)&#10;print(f&quot;Classification directory: {os.path.abspath(CLASSIFICATION_DIR)}&quot;)&#10;print(f&quot;Regression directory: {os.path.abspath(REGRESSION_DIR)}&quot;)&#10;&#10;# -----------------------------&#10;# 0) Load artifacts &amp; data&#10;# -----------------------------&#10;&#10;# Classifier (primary: CVD)&#10;clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_enhanced.pkl')&#10;if not os.path.exists(clf_model_path):&#10;    clf_model_path = os.path.join(CLASSIFICATION_DIR, 'best_xgb_model.pkl')&#10;&#10;clf = joblib.load(clf_model_path)&#10;print(f&quot;Loaded classifier from: {clf_model_path}&quot;)&#10;&#10;# Load test data for classifier&#10;X_test_cls_path = os.path.join(CLASSIFICATION_DIR, 'X_test.parquet')&#10;Y_test_path = os.path.join(CLASSIFICATION_DIR, 'Y_test.parquet')&#10;&#10;X_test_cls = pd.read_parquet(X_test_cls_path)&#10;Y_test = pd.read_parquet(Y_test_path).squeeze()&#10;print(f&quot;Loaded classifier test data: X_test={X_test_cls.shape}, Y_test={Y_test.shape}&quot;)&#10;&#10;# Regressor (secondary: ap_hi)&#10;reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_final_model.json')&#10;if not os.path.exists(reg_model_path):&#10;    reg_model_path = os.path.join(REGRESSION_DIR, 'xgboost_train_model.json')&#10;&#10;reg = xgb.XGBRegressor()&#10;reg.load_model(reg_model_path)&#10;print(f&quot;Loaded regressor from: {reg_model_path}&quot;)&#10;&#10;# Regressor feature info + test matrices&#10;feature_info_path = os.path.join(REGRESSION_DIR, 'feature_info.pkl')&#10;with open(feature_info_path, 'rb') as f:&#10;    feature_info_reg = joblib.load(f) if 'joblib.' in joblib.__name__ else __import__('pickle').load(f)&#10;&#10;feature_names_reg = feature_info_reg['feature_names']&#10;X_test_reg_path = os.path.join(REGRESSION_DIR, 'X_test.parquet')&#10;X_test_reg = pd.read_parquet(X_test_reg_path)&#10;&#10;# Check if model has feature names that are different from our expected ones&#10;model_feature_names = None&#10;if hasattr(reg, 'get_booster') and hasattr(reg.get_booster(), 'feature_names'):&#10;    model_feature_names = reg.get_booster().feature_names&#10;    print(f&quot;Regressor model uses these feature names: {model_feature_names[:5]}... (showing first 5)&quot;)&#10;&#10;# If model expects generic feature names like 'feature_0', adapt our dataframe&#10;if model_feature_names and model_feature_names[0].startswith('feature_'):&#10;    # Create a mapping of original columns to 'feature_X' format&#10;    generic_names = [f'feature_{i}' for i in range(len(X_test_reg.columns))]&#10;    X_test_reg_generic = X_test_reg.copy()&#10;    X_test_reg_generic.columns = generic_names&#10;    print(&quot;Using generic feature names for regressor prediction&quot;)&#10;    # Use this version for prediction&#10;    X_test_reg_for_prediction = X_test_reg_generic&#10;else:&#10;    # Use original column names&#10;    X_test_reg.columns = feature_names_reg&#10;    X_test_reg_for_prediction = X_test_reg&#10;&#10;# Optional: ap_hi ground truth (for decile prevalence plots)&#10;y_test_aphi_path = os.path.join(REGRESSION_DIR, 'y_test.parquet')&#10;y_test_aphi = None&#10;if os.path.exists(y_test_aphi_path):&#10;    y_test_aphi = pd.read_parquet(y_test_aphi_path).squeeze()  # ap_hi true values&#10;    print(f&quot;Loaded ap_hi ground truth: {y_test_aphi.shape}&quot;)&#10;&#10;# ----------------------------------------&#10;# 1) Make predictions on the same cohort&#10;# ----------------------------------------&#10;print(&quot;\nGenerating predictions...&quot;)&#10;&#10;# Classifier probabilities (P(CVD=1)) on its test set&#10;try:&#10;    prob_cardio = clf.predict_proba(X_test_cls)[:, 1]&#10;    print(f&quot;Generated {len(prob_cardio)} classifier predictions&quot;)&#10;except Exception as e:&#10;    print(f&quot;Warning: Error making classifier predictions: {e}&quot;)&#10;    print(&quot;Training a simple model on test data for demonstration...&quot;)&#10;    from sklearn.ensemble import RandomForestClassifier&#10;    simple_clf = RandomForestClassifier(n_estimators=50, random_state=42)&#10;    simple_clf.fit(X_test_cls, Y_test)&#10;    prob_cardio = simple_clf.predict_proba(X_test_cls)[:, 1]&#10;    print(f&quot;Generated {len(prob_cardio)} classifier predictions using simple model&quot;)&#10;&#10;# Regressor predictions on its test set&#10;pred_ap_hi = reg.predict(X_test_reg_for_prediction)&#10;print(f&quot;Generated {len(pred_ap_hi)} regressor predictions&quot;)&#10;&#10;# Attempt to align rows by index/ID if available; otherwise align by position&#10;def best_align(a, b):&#10;    &quot;&quot;&quot;&#10;    Align two arrays/Series by index if both are pandas with equal ordered index.&#10;    Else, align by position with a length check.&#10;    &quot;&quot;&quot;&#10;    if isinstance(a, pd.Series) and isinstance(b, pd.Series):&#10;        if len(a) == len(b) and (a.index.equals(b.index)):&#10;            return a.values, b.values&#10;    # Fallback: position-based&#10;    n = min(len(a), len(b))&#10;    if len(a) != len(b):&#10;        print(f&quot;WARNING: Length mismatch (a={len(a)}, b={len(b)}). &quot;&#10;              f&quot;Falling back to positional alignment on first {n} rows.&quot;)&#10;    return np.asarray(a)[:n], np.asarray(b)[:n]&#10;&#10;prob_cardio_aligned, pred_ap_hi_aligned = best_align(&#10;    pd.Series(prob_cardio), pd.Series(pred_ap_hi)&#10;)&#10;&#10;# If you also want aligned true labels for CVD (for bin prevalence):&#10;Y_test_aligned, _ = best_align(Y_test, pd.Series(pred_ap_hi))&#10;&#10;# Optionally add covariates for partial correlation&#10;covariates_df = pd.DataFrame(index=range(len(prob_cardio_aligned)))&#10;for candidate in ['bmi', 'age_years', 'gender_2', 'cholesterol_2', 'cholesterol_3', 'gluc_2', 'gluc_3']:&#10;    if candidate in X_test_cls.columns:&#10;        covariates_df[candidate] = X_test_cls[candidate].values[:len(covariates_df)]&#10;&#10;# Final analysis frame&#10;df_corr = pd.DataFrame({&#10;    'prob_cardio': prob_cardio_aligned,&#10;    'pred_ap_hi':  pred_ap_hi_aligned,&#10;    'y_cardio':    Y_test_aligned&#10;})&#10;df_corr = pd.concat([df_corr, covariates_df], axis=1)&#10;&#10;print(f&quot;Aligned rows for analysis: {len(df_corr)}&quot;)&#10;&#10;# ----------------------------------------&#10;# 2) Correlation statistics&#10;# ----------------------------------------&#10;pearson_r, pearson_p = pearsonr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;spearman_r, spearman_p = spearmanr(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;kendall_t, kendall_p = kendalltau(df_corr['pred_ap_hi'], df_corr['prob_cardio'])&#10;&#10;print(&quot;\nAssociation between predicted systolic BP and CVD probability&quot;)&#10;print(&quot;-------------------------------------------------------------&quot;)&#10;print(f&quot;Pearson r   = {pearson_r:.3f} (p={pearson_p:.3g})&quot;)&#10;print(f&quot;Spearman ρ  = {spearman_r:.3f} (p={spearman_p:.3g})&quot;)&#10;print(f&quot;Kendall τ   = {kendall_t:.3f} (p={kendall_p:.3g})&quot;)&#10;&#10;# ----------------------------------------&#10;# 3) Partial correlation (residual approach)&#10;#    Control for covariates (age, BMI, sex, cholesterol, glucose if available)&#10;# ----------------------------------------&#10;covars = [c for c in ['age_years','bmi','gender_2','cholesterol_2','cholesterol_3','gluc_2','gluc_3']&#10;          if c in df_corr.columns]&#10;&#10;if len(covars) &gt;= 1:&#10;    # Residualize pred_ap_hi on covars&#10;    Xc = df_corr[covars].fillna(df_corr[covars].median())&#10;    lr1 = LinearRegression().fit(Xc, df_corr['pred_ap_hi'])&#10;    res_ap_hi = df_corr['pred_ap_hi'] - lr1.predict(Xc)&#10;&#10;    # Residualize prob_cardio on covars (treat probability as continuous for partial-corr)&#10;    lr2 = LinearRegression().fit(Xc, df_corr['prob_cardio'])&#10;    res_prob = df_corr['prob_cardio'] - lr2.predict(Xc)&#10;&#10;    pr_r, pr_p = pearsonr(res_ap_hi, res_prob)&#10;    print(&quot;\nPartial correlation (controlling for covariates)&quot;)&#10;    print(&quot;------------------------------------------------&quot;)&#10;    print(f&quot;Partial Pearson r = {pr_r:.3f} (p={pr_p:.3g})&quot;)&#10;    print(f&quot;Controlled for: {', '.join(covars)}&quot;)&#10;else:&#10;    print(&quot;\nPartial correlation: skipped (no covariates available in current matrices)&quot;)&#10;&#10;# ----------------------------------------&#10;# 4) Visualizations&#10;# ----------------------------------------&#10;print(&quot;\nCreating visualizations...&quot;)&#10;&#10;# A) Scatter with polynomial regression line (no statsmodels dependency)&#10;plt.figure(figsize=(8.5, 7.5))&#10;try:&#10;    # Try using lowess if statsmodels is available&#10;    import statsmodels.api as sm&#10;    print(&quot;Using LOWESS smoothing for scatter plot&quot;)&#10;    sns.regplot(x='pred_ap_hi', y='prob_cardio', data=df_corr,&#10;                scatter_kws={'alpha':0.35, 's':20}, lowess=True, line_kws={'color':'red','lw':2})&#10;except (ImportError, RuntimeError):&#10;    # Fallback to polynomial regression if statsmodels is not available&#10;    print(&quot;Statsmodels not available, using polynomial regression instead&quot;)&#10;    sns.regplot(x='pred_ap_hi', y='prob_cardio', data=df_corr,&#10;                scatter_kws={'alpha':0.35, 's':20}, order=2, line_kws={'color':'red','lw':2})&#10;    &#10;plt.xlabel('Predicted Systolic BP (mmHg)')&#10;plt.ylabel('Predicted Probability of CVD')&#10;plt.title('Predicted CVD Probability vs Predicted Systolic BP')&#10;plt.grid(alpha=0.3)&#10;plt.tight_layout()&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'predBP_vs_probCVD_scatter.svg'), format='svg', bbox_inches='tight')&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'predBP_vs_probCVD_scatter.png'), bbox_inches='tight')&#10;plt.show()&#10;&#10;# B) Decile plot: CVD probability &amp; prevalence across ap_hi deciles&#10;df_bins = df_corr.copy()&#10;df_bins['ap_decile'] = pd.qcut(df_bins['pred_ap_hi'], q=10, duplicates='drop')&#10;grouped = df_bins.groupby('ap_decile', observed=True).agg(&#10;    mean_pred_bp=('pred_ap_hi','mean'),&#10;    mean_prob_cvd=('prob_cardio','mean'),&#10;    n=('prob_cardio','size'),&#10;    cvd_prev=('y_cardio','mean')  # requires y_cardio to be 0/1&#10;).reset_index()&#10;&#10;# Sort by mean predicted BP (qcut already sorts by range, but be explicit)&#10;grouped = grouped.sort_values('mean_pred_bp').reset_index(drop=True)&#10;&#10;plt.figure(figsize=(10, 7))&#10;ax = plt.gca()&#10;ax2 = ax.twinx()&#10;&#10;ax.plot(grouped.index+1, grouped['mean_prob_cvd'], color='tab:blue', lw=3, marker='o', label='Mean predicted P(CVD)')&#10;if 'cvd_prev' in grouped and not grouped['cvd_prev'].isna().all():&#10;    ax2.plot(grouped.index+1, grouped['cvd_prev'], color='tab:orange', lw=3, marker='s', label='Observed CVD prevalence')&#10;&#10;ax.set_xlabel('Predicted Systolic BP Decile (lowest → highest)')&#10;ax.set_ylabel('Mean Predicted P(CVD)', color='tab:blue')&#10;ax2.set_ylabel('Observed CVD Prevalence', color='tab:orange')&#10;plt.title('CVD risk across deciles of predicted systolic BP')&#10;ax.grid(alpha=0.3)&#10;lines, labels = ax.get_legend_handles_labels()&#10;lines2, labels2 = ax2.get_legend_handles_labels()&#10;ax2.legend(lines+lines2, labels+labels2, loc='upper left')&#10;plt.tight_layout()&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.svg'), format='svg', bbox_inches='tight')&#10;plt.savefig(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.png'), bbox_inches='tight')&#10;plt.show()&#10;&#10;# Save the decile table&#10;grouped.to_csv(os.path.join(OUTPUT_DIR, 'cvd_vs_predBP_deciles.csv'), index=False)&#10;print(&quot;Saved: predBP_vs_probCVD_scatter_lowess.(svg/png) and cvd_vs_predBP_deciles.(svg/png/csv)&quot;)&#10;&#10;# ----------------------------------------&#10;# 5) Optional: quantify incremental value of predicted ap_hi&#10;#    Fit a small logistic model on test set: prob_CVD ~ predicted ap_hi&#10;#    Then compare AUC to the classifier's AUC on the same set&#10;# ----------------------------------------&#10;try:&#10;    from sklearn.linear_model import LogisticRegression&#10;    from sklearn.preprocessing import StandardScaler&#10;    from sklearn.pipeline import Pipeline&#10;&#10;    # AUC of your classifier on test&#10;    auc_cls = roc_auc_score(df_corr['y_cardio'], df_corr['prob_cardio'])&#10;&#10;    # AUC using only predicted ap_hi&#10;    pipe = Pipeline([('scaler', StandardScaler()), ('lr', LogisticRegression(max_iter=200))])&#10;    pipe.fit(df_corr[['pred_ap_hi']], df_corr['y_cardio'])&#10;    auc_bp_only = roc_auc_score(df_corr['y_cardio'], pipe.predict_proba(df_corr[['pred_ap_hi']])[:,1])&#10;&#10;    print(&quot;\nIncremental value check (same test cohort)&quot;)&#10;    print(&quot;------------------------------------------&quot;)&#10;    print(f&quot;AUC (full classifier)      : {auc_cls:.3f}&quot;)&#10;    print(f&quot;AUC (predicted ap_hi only) : {auc_bp_only:.3f}&quot;)&#10;    print(f&quot;Difference                 : {auc_cls - auc_bp_only:.3f}&quot;)&#10;    print(&quot;Interpretation: the closer ap_hi-only AUC is to the full model AUC, &quot;&#10;          &quot;the more the classifier's risk signal is mediated through systolic BP.&quot;)&#10;except Exception as e:&#10;    print(f&quot;Incremental value check skipped: {e}&quot;)&#10;&#10;print(&quot;\nPrediction correlation analysis completed!&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>